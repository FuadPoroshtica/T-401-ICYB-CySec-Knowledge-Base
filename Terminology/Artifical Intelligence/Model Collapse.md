## Model Collapse
(A.k.a. â€œAI inbreedingâ€... ğŸ˜¬)
[Shumailov et al., â€œThe Curse of Recursionâ€](https://arxiv.org/abs/2305.17493):
- The web is filling with AI-generated content.
- Future models are trained on the output of current models.
- *The Result*: Model Collapse. The variance of the model disappears; it loses touch with reality and becomes â€œdumber.â€

**Security Context**: This is a long-term Data Supply Chain vulnerability.
If we build security tools (e.g., malware classifiers) on future datasets, they may be trained on â€œsynthetic garbage,â€ rendering them ineffective.


